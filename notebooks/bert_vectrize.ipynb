{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyM6FWt2mdOuwFlopJb0fFS2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"438dad164ab94b9999d9a53cc5fccc9e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2ca29811fcb14b8e84ddc91f21a5190d","IPY_MODEL_acf050c19dea410a8ec816390a335a57","IPY_MODEL_abf41a8be4d4471393efc56ece760253"],"layout":"IPY_MODEL_ae32517aae9643cea3e23547273f3c25"}},"2ca29811fcb14b8e84ddc91f21a5190d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bcd9ef3e4bd548da971a58eea1532c68","placeholder":"​","style":"IPY_MODEL_d1576a378f2248d086b2671002f98a41","value":"Downloading: 100%"}},"acf050c19dea410a8ec816390a335a57":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f191702014284f42a18aa07c46378b31","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dc40a75b0e894517b459734ef55d346c","value":231508}},"abf41a8be4d4471393efc56ece760253":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4a674e2c7234764b801e94e89bdcc95","placeholder":"​","style":"IPY_MODEL_701f43242c6143cca1c68fbab2a3c97f","value":" 232k/232k [00:00&lt;00:00, 527kB/s]"}},"ae32517aae9643cea3e23547273f3c25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcd9ef3e4bd548da971a58eea1532c68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1576a378f2248d086b2671002f98a41":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f191702014284f42a18aa07c46378b31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc40a75b0e894517b459734ef55d346c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c4a674e2c7234764b801e94e89bdcc95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"701f43242c6143cca1c68fbab2a3c97f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3401719be3b34e0599ee85468e93e3c6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6fd0b3d0f06849978b65e7f43363619b","IPY_MODEL_8c0e73479fbf443d971202f2b5e7613b","IPY_MODEL_5a78e03879b1403a8f0371388e57edd3"],"layout":"IPY_MODEL_4aac045d8bbe4466b20a774da90e1ff1"}},"6fd0b3d0f06849978b65e7f43363619b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0db1689c8b66404ca8697b0b7b6a71d8","placeholder":"​","style":"IPY_MODEL_aa49bfd0794d4d3886d5d378600c6a05","value":"Downloading: 100%"}},"8c0e73479fbf443d971202f2b5e7613b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e8596fc455e478d9650c26ec69749ac","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_95c56ffa96b74ef19b98a26a72341ae6","value":28}},"5a78e03879b1403a8f0371388e57edd3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec504e3a28fb4e51a3a99a2458cd17a2","placeholder":"​","style":"IPY_MODEL_636f386dd7ba4f0f98153febbc71eb6f","value":" 28.0/28.0 [00:00&lt;00:00, 736B/s]"}},"4aac045d8bbe4466b20a774da90e1ff1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0db1689c8b66404ca8697b0b7b6a71d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa49bfd0794d4d3886d5d378600c6a05":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e8596fc455e478d9650c26ec69749ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95c56ffa96b74ef19b98a26a72341ae6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ec504e3a28fb4e51a3a99a2458cd17a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"636f386dd7ba4f0f98153febbc71eb6f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd1279fa80524e548af810e81ce29762":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_578baccbada647aba3653edde220ccf7","IPY_MODEL_a95e4b280f9e495fab31c4f065a424ae","IPY_MODEL_c1b74214a7bd45cd81608d82bcf284b6"],"layout":"IPY_MODEL_a6b3976f4b0149439d9cf84e2e198fa8"}},"578baccbada647aba3653edde220ccf7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3559bedb7b343319a14bb189b06a92f","placeholder":"​","style":"IPY_MODEL_9a5f5530f5d1411a97212c663a36173c","value":"Downloading: 100%"}},"a95e4b280f9e495fab31c4f065a424ae":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_21e80fcf5dc44fcab660a079e120904f","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_43444ac60fa74d7db8b5c6e216d42b11","value":570}},"c1b74214a7bd45cd81608d82bcf284b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_72853b9ddb1447aebcbbf8197da0bb1c","placeholder":"​","style":"IPY_MODEL_1faf4307a48842f4ab22b08d22d5d3b0","value":" 570/570 [00:00&lt;00:00, 17.3kB/s]"}},"a6b3976f4b0149439d9cf84e2e198fa8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3559bedb7b343319a14bb189b06a92f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a5f5530f5d1411a97212c663a36173c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"21e80fcf5dc44fcab660a079e120904f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43444ac60fa74d7db8b5c6e216d42b11":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"72853b9ddb1447aebcbbf8197da0bb1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1faf4307a48842f4ab22b08d22d5d3b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf97948d342340dd8b1c02cdbab7ba99":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_140cd3594430489ea2edf55e87fdf4e7","IPY_MODEL_508e0fd2dbb74dceb90b5b4d36267c5d","IPY_MODEL_0c6eddc14a564c638e5c522e009ef00b"],"layout":"IPY_MODEL_a89998778a684999aae157bdc58ab890"}},"140cd3594430489ea2edf55e87fdf4e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb67e34ab1f14a819fc7992da914cdad","placeholder":"​","style":"IPY_MODEL_1b03418c59b44910b0451d4bfe0b9f3b","value":"Downloading: 100%"}},"508e0fd2dbb74dceb90b5b4d36267c5d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8abdbc098c204f73ad463e132ab247f6","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5aab5712befa4993a0f9804306418ba8","value":440473133}},"0c6eddc14a564c638e5c522e009ef00b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e8c7dd6050b45e7ba90c842a82c3490","placeholder":"​","style":"IPY_MODEL_7d31feba6aee4bd49586e079b826a0da","value":" 440M/440M [00:07&lt;00:00, 62.2MB/s]"}},"a89998778a684999aae157bdc58ab890":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb67e34ab1f14a819fc7992da914cdad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b03418c59b44910b0451d4bfe0b9f3b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8abdbc098c204f73ad463e132ab247f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5aab5712befa4993a0f9804306418ba8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0e8c7dd6050b45e7ba90c842a82c3490":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d31feba6aee4bd49586e079b826a0da":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DiY2VGJ-bWbC","executionInfo":{"status":"ok","timestamp":1669804260343,"user_tz":-540,"elapsed":27811,"user":{"displayName":"Subaru Ishizuka","userId":"14372966424326098742"}},"outputId":"c05d81d6-6676-47d3-aae2-8c9ecfe2a101"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/competitions/probspace_pricing/notebooks/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eRhedmz1bZh9","executionInfo":{"status":"ok","timestamp":1669804261376,"user_tz":-540,"elapsed":1038,"user":{"displayName":"Subaru Ishizuka","userId":"14372966424326098742"}},"outputId":"d7b4b1aa-670d-4317-b461-e701c0dec0fe"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/competitions/probspace_pricing/notebooks\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TfCwZ-lGXDGE","executionInfo":{"status":"ok","timestamp":1669804273868,"user_tz":-540,"elapsed":12495,"user":{"displayName":"Subaru Ishizuka","userId":"14372966424326098742"}},"outputId":"f8676346-61dc-4c2c-deb2-bd7ad56397cd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n","\u001b[K     |████████████████████████████████| 5.5 MB 22.7 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 71.9 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 54.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.24.0\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import torch\n","import transformers\n","\n","from transformers import BertTokenizer\n","from tqdm import tqdm\n","tqdm.pandas()"],"metadata":{"id":"EXFlCGqaYDki","executionInfo":{"status":"ok","timestamp":1669804278505,"user_tz":-540,"elapsed":4644,"user":{"displayName":"Subaru Ishizuka","userId":"14372966424326098742"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1-kBawBtyYgi","executionInfo":{"status":"ok","timestamp":1669804278505,"user_tz":-540,"elapsed":11,"user":{"displayName":"Subaru Ishizuka","userId":"14372966424326098742"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# 前処理関数"],"metadata":{"id":"MRVY3sPjyZdq"}},{"cell_type":"code","source":["def preprocess_text(df, col):\n","    # nanを\"NAN\"に置換\n","    df = df.replace({col: {np.nan: 'NAN'}})\n","    return df"],"metadata":{"id":"B0VJhqxXyYd8","executionInfo":{"status":"ok","timestamp":1669804278506,"user_tz":-540,"elapsed":10,"user":{"displayName":"Subaru Ishizuka","userId":"14372966424326098742"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def preprocess_amenities(df, col):\n","    # 不要な文字を削除（Amenitiesにつかう）\n","    df[col] = df[col].apply(lambda x: x.replace(\"[\", \"\").replace('\"', \"\").replace(']', \"\"))\n","\n","    return df"],"metadata":{"id":"12Cj8c9vyYb4","executionInfo":{"status":"ok","timestamp":1669804278506,"user_tz":-540,"elapsed":9,"user":{"displayName":"Subaru Ishizuka","userId":"14372966424326098742"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def preprocess_pt_am_bt(df):\n","    # 連結する\n","    text_list = []\n","    for i in range(len(df)):\n","        text = \"PropertyType is \" + df[\"PropertyType\"][i]  + \". Amenities are \" + df[\"Amenities\"][i] + \". Bathroom is \" + df[\"BathroomsText\"][i]\n","        text_list.append(text)\n","    df[\"conbine_PT_Am_BT\"] = np.array(text_list)\n","\n","    return df"],"metadata":{"id":"Q94vHeaOj0er","executionInfo":{"status":"ok","timestamp":1669804278506,"user_tz":-540,"elapsed":8,"user":{"displayName":"Subaru Ishizuka","userId":"14372966424326098742"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"VEgHYjyj8XZ-","executionInfo":{"status":"ok","timestamp":1669804278506,"user_tz":-540,"elapsed":8,"user":{"displayName":"Subaru Ishizuka","userId":"14372966424326098742"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["# 分散表現クラス"],"metadata":{"id":"SpHzcs7ShagB"}},{"cell_type":"code","source":["class BertSequenceVectorizer:\n","    def __init__(self, model_name):\n","        self.device = 'cuda' # 'cuda' if torch.cuda.is_available() else 'cpu'\n","        self.model_name = model_name\n","        self.tokenizer = BertTokenizer.from_pretrained(self.model_name)\n","        self.bert_model = transformers.BertModel.from_pretrained(self.model_name)\n","        self.bert_model = self.bert_model.to(self.device)\n","        self.max_len = 512\n","\n","\n","    def vectorize(self, sentence : str) -> np.array:\n","\n","        # 1.&2.トークナイズを行って、単語のベクトル化を行う\n","        # ※トークン以外にもトークンタイプとアテンションマスクの情報も付与されている\n","        input = self.tokenizer(sentence, return_tensors=\"pt\", max_length=self.max_len)\n","        # GPUに乗せる\n","        input[\"input_ids\"] = input[\"input_ids\"].to(\"cuda\")\n","        input[\"token_type_ids\"] = input[\"token_type_ids\"].to(\"cuda\")\n","        input[\"attention_mask\"] = input[\"attention_mask\"].to(\"cuda\")\n","\n","        with torch.no_grad(): # 計算の途中結果が保存されなくなる\n","            # BERTに通す\n","            outputs = self.bert_model(**input) # 引数に**を付与すると、キーとバリューがキーワード引数とその値となる\n","            # BERTの最終層を取り出す\n","            last_hidden_states = outputs.last_hidden_state\n","\n","            # マスクを取り出す\n","            attention_mask = input.attention_mask.unsqueeze(-1)\n","            # [PAD]を除いたトークン数\n","            valid_token_num = attention_mask.sum(1)\n","\n","            # 平均値を算出:BERTから出力されたベクトルを平均する場合\n","            # attention_maskは[PAD]トークンの時に0を返すので、単語ベクトルとの積を取ると[PAD]分が除かれる\n","            sentence_vec = (last_hidden_states*attention_mask).sum(1) / valid_token_num\n","\n","            # 平均値を算出:トークン列の特殊トークン[CLS]に対応するベクトルを使用する場合\n","            # sentence_vec = last_hidden_states[0][0]\n","        \n","            # GPU利用時\n","            sentence_vec = sentence_vec.detach().cpu().numpy()[0]\n","\n","        return sentence_vec"],"metadata":{"id":"VazDKd37YDha","executionInfo":{"status":"ok","timestamp":1669804278507,"user_tz":-540,"elapsed":9,"user":{"displayName":"Subaru Ishizuka","userId":"14372966424326098742"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# 次元削減する関数"],"metadata":{"id":"M1Hbk698xhph"}},{"cell_type":"code","source":["def decompose_func(df, col, n_components):\n","\n","    # 次元削減\n","    model = TruncatedSVD(n_components=n_components, random_state=123)\n","    decomponents_array = model.fit_transform(np.vstack(df[col]))\n","\n","    # dfに格納\n","    decomponents_df = pd.DataFrame(decomponents_array)\n","    # カラム名をつける\n","    decomponents_df.columns = [\"bert_svd_{}_{}\".format(col, i) for i in range(decomponents_df.shape[1])]\n","\n","    return decomponents_df"],"metadata":{"id":"B2t15r9QxK23","executionInfo":{"status":"ok","timestamp":1669804278507,"user_tz":-540,"elapsed":8,"user":{"displayName":"Subaru Ishizuka","userId":"14372966424326098742"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["#分散表現＋次元削減をする関数"],"metadata":{"id":"p5NV-_KxlMWL"}},{"cell_type":"code","source":["from sklearn.decomposition import PCA, TruncatedSVD, NMF"],"metadata":{"id":"ul4b6VphlJaL","executionInfo":{"status":"ok","timestamp":1669804279518,"user_tz":-540,"elapsed":1019,"user":{"displayName":"Subaru Ishizuka","userId":"14372966424326098742"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def vect_decompose(all_df, col, model_name, n_components=20):\n","\n","    df = all_df.copy()\n","\n","    # 分散表現\n","    BSV = BertSequenceVectorizer(model_name=model_name)\n","    df[col] = df[col].apply(lambda x: BSV.vectorize(x))\n","\n","    # 次元削減\n","    decomponents_df = decompose_func(df, col, n_components=n_components)\n","\n","    # merge\n","    df = pd.merge(all_df[\"ID\"], decomponents_df, left_index=True, right_index=True)\n","\n","    return df"],"metadata":{"id":"Hbe13g7zYDXh","executionInfo":{"status":"ok","timestamp":1669804279518,"user_tz":-540,"elapsed":7,"user":{"displayName":"Subaru Ishizuka","userId":"14372966424326098742"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"sDQmB1uFYDQh","executionInfo":{"status":"ok","timestamp":1669804279519,"user_tz":-540,"elapsed":6,"user":{"displayName":"Subaru Ishizuka","userId":"14372966424326098742"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["# main"],"metadata":{"id":"9d4i-Qv2qJs4"}},{"cell_type":"code","source":["raw_path = \"/content/drive/MyDrive/competitions/probspace_pricing/data/raw/\"\n","features_path = \"/content/drive/MyDrive/competitions/probspace_pricing/data/features/\""],"metadata":{"id":"wzhcd7ZHlkHq","executionInfo":{"status":"ok","timestamp":1669804279519,"user_tz":-540,"elapsed":5,"user":{"displayName":"Subaru Ishizuka","userId":"14372966424326098742"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# データの読み込み\n","train_df = pd.read_csv(raw_path + \"train.csv\")\n","test_df = pd.read_csv(raw_path + \"test.csv\")\n","review_df = pd.read_csv(raw_path + \"review.csv\")\n","\n","all_df = pd.concat([train_df, test_df]).reset_index()"],"metadata":{"id":"7mcOKbMubL0a","executionInfo":{"status":"ok","timestamp":1669804286453,"user_tz":-540,"elapsed":6939,"user":{"displayName":"Subaru Ishizuka","userId":"14372966424326098742"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["col_list1 = [\"OwnerDetail\",\"Description\"] \n","col_list2 = [\"PropertyType\",\"Amenities\",\"BathroomsText\"]"],"metadata":{"id":"Pb_IPxv4XRo_","executionInfo":{"status":"ok","timestamp":1669804286454,"user_tz":-540,"elapsed":6,"user":{"displayName":"Subaru Ishizuka","userId":"14372966424326098742"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["OwnerDetail Description"],"metadata":{"id":"kfxcLKZQFsGA"}},{"cell_type":"code","source":["# 多言語\n","for col in col_list1:\n","    \n","    print(\"【{} start】\".format(col))\n","\n","    model_name = 'bert-base-uncased' # 'bert-base-multilingual-cased'\n","\n","    # NaNを変換\n","    all_df = preprocess_text(all_df, col)\n","\n","    # 分散表現＋SVD\n","    decompose_df = vect_decompose(all_df, col, model_name=model_name, n_components=20)\n","\n","    # pickleファイルに格納\n","    decompose_df.to_pickle(features_path + \"{}_vect_svd_{}.pkl\".format(col, model_name))"],"metadata":{"id":"ewsu3PLUZRfq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1669806756759,"user_tz":-540,"elapsed":2293568,"user":{"displayName":"Subaru Ishizuka","userId":"14372966424326098742"}},"outputId":"f28e13a7-36ba-4b83-b8cf-51776d077167"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["【OwnerDetail start】\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["【Description start】\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]}]},{"cell_type":"markdown","source":["PropertyType Amenities BathroomsText"],"metadata":{"id":"jNEtvn5_FyAO"}},{"cell_type":"code","source":["# 前処理\n","all_df = preprocess_amenities(all_df, \"Amenities\")"],"metadata":{"id":"66ZmVfNI4K1H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 英語\n","for col in col_list2:\n","    \n","    print(\"【{} start】\".format(col))\n","\n","    # NaNを変換\n","    all_df = preprocess_text(all_df, col)\n","\n","    # 分散表現＋SVD\n","    decompose_df = vect_decompose(all_df, col, model_name='bert-base-uncased', n_components=20)\n","\n","    # pickleファイルに格納\n","    decompose_df.to_pickle(features_path + \"{}_vect_svd.pkl\".format(col))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":433,"referenced_widgets":["438dad164ab94b9999d9a53cc5fccc9e","2ca29811fcb14b8e84ddc91f21a5190d","acf050c19dea410a8ec816390a335a57","abf41a8be4d4471393efc56ece760253","ae32517aae9643cea3e23547273f3c25","bcd9ef3e4bd548da971a58eea1532c68","d1576a378f2248d086b2671002f98a41","f191702014284f42a18aa07c46378b31","dc40a75b0e894517b459734ef55d346c","c4a674e2c7234764b801e94e89bdcc95","701f43242c6143cca1c68fbab2a3c97f","3401719be3b34e0599ee85468e93e3c6","6fd0b3d0f06849978b65e7f43363619b","8c0e73479fbf443d971202f2b5e7613b","5a78e03879b1403a8f0371388e57edd3","4aac045d8bbe4466b20a774da90e1ff1","0db1689c8b66404ca8697b0b7b6a71d8","aa49bfd0794d4d3886d5d378600c6a05","1e8596fc455e478d9650c26ec69749ac","95c56ffa96b74ef19b98a26a72341ae6","ec504e3a28fb4e51a3a99a2458cd17a2","636f386dd7ba4f0f98153febbc71eb6f","fd1279fa80524e548af810e81ce29762","578baccbada647aba3653edde220ccf7","a95e4b280f9e495fab31c4f065a424ae","c1b74214a7bd45cd81608d82bcf284b6","a6b3976f4b0149439d9cf84e2e198fa8","d3559bedb7b343319a14bb189b06a92f","9a5f5530f5d1411a97212c663a36173c","21e80fcf5dc44fcab660a079e120904f","43444ac60fa74d7db8b5c6e216d42b11","72853b9ddb1447aebcbbf8197da0bb1c","1faf4307a48842f4ab22b08d22d5d3b0","cf97948d342340dd8b1c02cdbab7ba99","140cd3594430489ea2edf55e87fdf4e7","508e0fd2dbb74dceb90b5b4d36267c5d","0c6eddc14a564c638e5c522e009ef00b","a89998778a684999aae157bdc58ab890","bb67e34ab1f14a819fc7992da914cdad","1b03418c59b44910b0451d4bfe0b9f3b","8abdbc098c204f73ad463e132ab247f6","5aab5712befa4993a0f9804306418ba8","0e8c7dd6050b45e7ba90c842a82c3490","7d31feba6aee4bd49586e079b826a0da"]},"id":"c9jFslo26MKB","executionInfo":{"status":"ok","timestamp":1669452573802,"user_tz":-540,"elapsed":2691046,"user":{"displayName":"Subaru Ishizuka","userId":"14372966424326098742"}},"outputId":"e09e2091-caec-4bb9-8a70-ad7a2f2c1076"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["PropertyType start\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"438dad164ab94b9999d9a53cc5fccc9e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3401719be3b34e0599ee85468e93e3c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd1279fa80524e548af810e81ce29762"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf97948d342340dd8b1c02cdbab7ba99"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["Amenities start\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["BathroomsText start\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]}]},{"cell_type":"markdown","source":["Review"],"metadata":{"id":"m6UfGCyIEzKl"}},{"cell_type":"code","source":["col = \"Review\"\n","\n","model_name = 'bert-base-uncased'\n","\n","# NaNを変換\n","review_df = preprocess_text(review_df, col)\n","\n","# 分散表現＋SVD\n","decompose_df = vect_decompose(review_df, col, model_name=model_name, n_components=20)\n","\n","# csvに格納\n","decompose_df.to_pickle(features_path + \"{}_vect_svd_{}.pkl\".format(col, model_name)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g_YlTt7BhbK5","executionInfo":{"status":"ok","timestamp":1669810654782,"user_tz":-540,"elapsed":3173161,"user":{"displayName":"Subaru Ishizuka","userId":"14372966424326098742"}},"outputId":"c7ec6a5a-b032-4fbd-c08f-a34c31224b3d"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]}]},{"cell_type":"markdown","source":["conbine_PT_Am_BT"],"metadata":{"id":"v1Bvfw-eEvBG"}},{"cell_type":"code","source":["# NaNを変換\n","all_df = preprocess_text(all_df, \"BathroomsText\")\n","\n","col = \"conbine_PT_Am_BT\"\n","\n","model_name = 'bert-base-uncased'\n","\n","# 前処理\n","all_df = preprocess_pt_am_bt(all_df)\n","\n","# 分散表現＋SVD\n","decompose_df = vect_decompose(all_df, col, model_name=model_name, n_components=20)\n","\n","# pickleファイルに格納\n","decompose_df.to_pickle(features_path + \"{}_vect_svd_{}.pkl\".format(col, model_name))"],"metadata":{"id":"FY9BUOTsXRma"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ozCPtARWXRkG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"tt8DsNcmXRhb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Y3cLCsH_XRe2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"m-jTq0emXRXG"},"execution_count":null,"outputs":[]}]}